\documentclass[12pt]{report}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath,amsfonts,amssymb, amsthm}

\let\conjugatet\overline
\usepackage{tikz-cd} 
\usepackage{mathtools}          %loads amsmath as well
\DeclarePairedDelimiter\Floor\lfloor\rfloor
\DeclarePairedDelimiter\Ceil\lceil\rceil
\usepackage[h margin=1 in, v margin=1 in]{geometry}
%-------Packages---------
\usepackage{enumerate}
\usepackage{mathrsfs}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{enumitem}
\usepackage{mathrsfs}
\usepackage{graphicx}
\usepackage{tikz-cd}
\usepackage{tensor}
\usepackage{cancel}
\usepackage{braket}
\usepackage{hyperref}
\usepackage{chngcntr}
\usepackage{titlesec}
\usepackage{mathpazo}
\usepackage{stmaryrd}
%--------Section labels--------------

\counterwithout{section}{chapter}

\newcommand{\periodafter}[1]{#1.}
\titleformat{\chapter}[frame]
  {\normalfont}
  {\filright\small\enspace\MakeUppercase{\chaptertitlename}~\thechapter\enspace}
  {20pt}
  {\Large\filcenter}
\titleformat{\section}[runin]
  {\normalfont\large\bfseries}{\thesection}{1em}{\periodafter}
\titlespacing*{\section}
  {0pt}{3.5ex plus 1ex minus .2ex}{0.5em}

%--------Theorem Environments--------
%theoremstyle{plain} --- default
\newtheorem{thm}{Theorem}[section]
\newtheorem*{thm*}{Theorem}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{lem}[thm]{Lemma}
\newtheorem*{lem*}{Lemma}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{quest}[thm]{Question}
\newtheorem{sol}[thm]{Solution}

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem*{defn*}{Definition}
\newtheorem{defns}[thm]{Definitions}
\newtheorem{con}[thm]{Construction}
\newtheorem{exmp}[thm]{Example}
\newtheorem{exmps}[thm]{Examples}
\newtheorem{notn}[thm]{Notation}
\newtheorem{notns}[thm]{Notations}
\newtheorem{addm}[thm]{Addendum}
\newtheorem{exer}[thm]{Exercise}

\theoremstyle{remark}
\newtheorem{rem}[thm]{Remark}
\newtheorem*{rem*}{Remark}
\newtheorem{rems}[thm]{Remarks}
\newtheorem{warn}[thm]{Warning}
\newtheorem{sch}[thm]{Scholium}



\makeatletter
\let\c@equation\c@thm
\makeatother
\numberwithin{equation}{section}
\graphicspath{{images/}}
\bibliographystyle{plain}
\def\acts{\curvearrowright}
\newtheorem*{theorem*}{Theorem}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\theoremstyle{definition}
%begin macros
\newcommand*{\isoarrow}[1]{\arrow[#1,"\rotatebox{90}{\(\sim\)}"
]}
\newcommand{\Lagr}{\mathcal{L}}
\newcommand{\inv}[1]{#1^{-1}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\bb}[1]{\mathbb{#1}}
\newcommand{\lalg}[1]{\mathfrak{#1}}
\newcommand{\brak}[1]{\left\langle #1 \right\rangle}
\DeclarePairedDelimiter\abs{\lvert}{\rvert}%
\DeclarePairedDelimiter\norm{\lVert}{\rVert}%
\newcommand{\ser}{\sum_{n=0}^\infty}
\newcommand*{\Perm}[2]{{}^{#1}\!P_{#2}}%
\newcommand*{\Comb}[2]{{}^{#1}C_{#2}}%
\newcommand{\mqed}{\hfill\newline\null \hfill$\square$\\ }
\makeatletter
\newcommand{\extp}{\@ifnextchar^\@extp{\@extp^{\,}}}
\def\@extp^#1{\mathop{\bigwedge\nolimits^{\!#1}}}
\makeatother
\renewcommand{\tilde}{\widetilde}
%end macros


\title{M392C: Complex Geometry}
\author{Reese Lance}

\date{Fall 2020}

\begin{document}
\maketitle
\abstract{Class taught by Berndt Siebert at the University of Texas at Austin, notes taken by Reese Lance. The notes are not live texed. They are post-mortem-texed, that is, taken by hand during class and typed later. Some of my own thoughts are interjected, but rarely. I initially thought to try to separate my thoughts from the professor's but it becomes too difficult. As such I will also try to expand on examples which are mentioned in passing in class and spell out proofs which are glossed over. This helps to justify the existence of this set of notes, as opposed to live-texed notes (which are often available for classes at this university), which are probably slightly better for a faithful representation of what is being taught in the classroom. Especially because some of my own content is interspersed throughout these notes, any corrections, questions, comments, suggestions, etc., can be sent via email (reese.lance@utexas.edu) or if you can find any other way to communicate with me, that is also fine. At the moment I'm trying to get the notes written, and worrying about the format later. I'm also not going to track theorem and lemma numbers, as I think that's mostly useless. If a proof somewhere says ``Applying Theorem $X$'', it can usually be determined from context what theorems need to be invoked, and if the reader doesn't find it readily apparent, then searching for the theorem in question will be a valuable experience. Also I always forget to write down the numbers. Also as I revisit and add in more stuff, the numbering becomes involved and I'd have to actually figure out how to number properly instead of just manually putting numbers, which is what would have been the plan. Siebert releases "Guiding Questions" periodically, which are meant to be concepts to refresh yourself with before the subsequent lectures. I will attempt to address some of these questions in the notes, but this is an intimidating proposition, as I'm already falling behind on notes, in classic fashion, so we will see if that actually ends up happening. Thanks to Arun Debray whose formatting choices inspired my own. }
\newpage
\begin{center}
\Large Table of Contents
\end{center}
\hyperref[sec:1]{\textcolor{blue}{1. Overview of Complex Analysis}}\\
\hyperref[sec:2]{\textcolor{blue}{2. Hartogs' Theorem and Domains of Holomorphy}}\\
\hyperref[sec:3]{\textcolor{blue}{3. Weierstrass Preparation Theorem}}\\
\hyperref[sec:4]{\textcolor{blue}{4. Lec 4}}\\
\chapter{Overview of Complex Analysis}
\section*{Lecture 1, Aug 27}
\label{sec:1}
When working with several complex variables, the use of $i$ as an index becomes problematic, since we want to assign $\sqrt{-1} = i$. So for instance, the standard coordinates 
$$
	\bb C^n = \left\{z_1,\dots,z_n\ |\ z_i = x_i + iy_i, x_i,y_i \in \bb R\right\}
$$
might appear confusing. However, it is always clear from context which $i$ is meant: There is never an instance where you we will be indexing over the complex numbers. One important concept we will discuss is the: \\
\textbf{Theorem: (Cauchy Integral Formula, version 1)} \textit{If $f: U \to \bb C$ is a holomorphic function, and $\gamma: I \to U$ is a simple, closed curve in $U$, then for any $z \in \Omega_{int}$ defined by the Jordan Curve theorem applied to $\gamma$ satisfies: }
$$
	f(z) = \frac{1}{2\pi i}\int_{\gamma} \frac{f(\zeta)}{(\zeta - z)} d\zeta 
$$
WLOG, we may treat $\gamma$ as the unit disk, in which case CIF is written as 
$$
		f(z) = \frac{1}{2\pi i}\int_{\norm{\zeta} = 1} \frac{f(\zeta)}{(\zeta - z)} d\zeta 
$$
Here, the curve we are interested in is $\gamma$, but we require $f$ to be defined on a larger, open set $U$, but this is an unnecessary requirement: for CIF to hold, we need only require that $f$ be continuous and holomorphic on $\Omega_{int}$. We can see version 1 implies version 2 	by taking increasingly large disks inside of $\Omega_{int}$: Apply version 1 of CIF on a unit disk of radius $1-\epsilon \subset \Omega_{int}$. Then we have the CIF formula for all points $z \in B(0,1-\epsilon)$. By perturbing the smaller disk slightly, a continuity argument says that the  new integral,
$$
	\frac{1}{2\pi i}\int_{\norm{\zeta} = 1-\epsilon} \frac{f(\zeta)}{(\zeta - z)} d\zeta 
$$
converges. But of course, the value of $f(z)$ doesn't change, so neither does the integral. Then taking the limit $\epsilon \to 0$ shows the result. This is the more natural way to state the CIF, since it doesn't require the extra ad-hoc neighborhood $U$. \\\\
In a first encounter with complex analysis, we typically write down definitions formally and manipulate them calculus style: 
$$
	\frac{\partial}{\partial z} := \frac{1}{2}\left(\frac{\partial}{\partial x} -i \frac{\partial}{\partial y }\right), \ \ \ \text{and   } 	\frac{\partial}{\partial \overline z} := \frac{1}{2}\left(\frac{\partial}{\partial x} +i \frac{\partial}{\partial y }\right)
$$
and similarly for the differential forms
$$
	dz = dx + i dy, \ \ \ \text{and   } d \overline z = dx -i dy 
$$
If we consider a differentiable function $f = g+ih: \bb C \to \bb C$, we can write down its Jacobian 
$$
	D_p f = \begin{pmatrix} g_x & g_y \\ h_x & h_y \end{pmatrix}(p)
$$
If we wish to change coordinates to $z = x + iy$, we might want to write
$$
	D_p f = \begin{pmatrix} \partial_z f & \partial_{\overline z} f \\ \partial_z \overline f & \partial_{\overline z} \overline f \end{pmatrix}
$$
But as we know, $\overline{(\partial_z f)} = \partial_{\overline z} \overline f$, so this Jacobian has inherent redundancy: the two entries which are diagonal from each other are related by the complex conjugate. In other words, this matrix has the form 
$$
	D_p f = \begin{pmatrix} a & b \\ \overline b & \overline a\end{pmatrix}
$$
So in order to compute the real jacobian, if you're working in complex coordinates, you must know $\partial_z f$ and $\partial _{\overline z}f$, it is not enough to just know one. If, in addition, $f$ is holomorphic, then the Cauchy-Riemann equations imply $\partial_{\overline z} f = 0$, so all the information about the total derivative of $f$ is contained in $\partial z f$. So for $f \in \mathcal{O}(\bb C)$\footnote{this denotes the set of holomorphic functions on $\bb C$, which is referred to by Siebert as a ``structure sheaf'', which is a phrase that scares me}, 
$$
	D_p f = \begin{pmatrix} a & 0 \\ 0 & \overline a \end{pmatrix}
$$
Now we move on to several variables, with the notion of holomorphicity:\\
\textbf{Definition: }If $U \subset \bb C^n$, then $f: U \to \bb C^n$ is \underline{holomorphic} if the function 
$$
	w \mapsto f(z_1, \dots, z_{i-1}, w, z_{i+1}, \dots, z_n) \text{  is holomorphic  } \forall i \in \{1, \dots, n\}
$$
i.e. if $f$ is holomorphic in each of its variables. Then, if $f \in \mathcal{O}(U)$, we can write down a version of CIF by applying the 1-d version repeatedly to each entry:
$$
	f(z) = \frac{1}{(2\pi i)^n}\int_{\norm{z_i - w_i} = \epsilon_i} \frac{f(\zeta_1,\dots,\zeta_n)}{(\zeta_1-z_1)\dots(\zeta_n-z_n)}d\zeta_1\dots d\zeta_n
$$
here, the natural domain is\\
\textbf{Definition: }A \underline{polydisc}, $D_\epsilon(w)$, is a product of disks,
$$
	\epsilon = (\epsilon_1,\dots,\epsilon_n),\ \ \ D_\epsilon(w) := \{z\ |\ \norm{z_i-w_i}< \epsilon_i\}
$$
\\
For $n > 1$, this is distinct from the unit disk, even when $\epsilon = (1,\dots,1)$: in $n = 2$, $(i-\epsilon,i-\epsilon) \in D_{(1,1)}(0)$, but $(i-\epsilon,i-\epsilon)$ has distance $\sim 2$ from the origin, and so is not in the unit disk. As such, their boundaries are also not the same: 
$$
	\partial\Delta^n = S^{2n-1} \not \cong \{z\in \bb C^n\ |\ \norm{z} = 1\}
$$
The RHS is sometimes referred to as the Shilov boundary. \\
As in one variable, the CIF gives us the power series expansions:
$$
	f(z) = \sum a_I z^I
$$
where $I$ is the multi-index $I = (i_1,\dots,i_n)$, and $a_I$ are complex coefficients that can be obtained using the CIF. \\
Another interesting feature unique to $n > 1$ complex analysis is the concept of domains of holomorphy. A domain of holomorphy, $\Omega$ is characterized by the property that there is a holomorphic function on $\Omega$ which cannot be extended to a larger set. \\
In the case of $\Delta^2$, this means that 
$$
	f\in \mathcal{O}(\Delta^2 \text{\textbackslash}\{0\}) \Rightarrow \ \ \ \ f \text{ extends over } 0
$$
i.e. the map given by restriction 
$$
	\mathcal{O}(\Delta^2) \to \mathcal{O}(\Delta^2 \text{\textbackslash} \{0\})\ \ \ \text{is a bijection}
$$
This fact is a consequence of \\
\textbf{Theorem (Hartogs): }\textit{Let $f$ be a holomorphic function on a set $G\setminus K$ where G is an open subset of $\bb C^n$, for $(n \geq 2)$ and K is a compact subset of G. If the complement $G \setminus K$ is connected, then f can be extended to a unique holomorphic function on G.}\\
Switching gears again, suppose you have a holomorphic function $f$ on a polydisc, and you want to study the zeros of this function. \\
\textbf{Definition: }A \underline{Weierstrass polynomial} is a function on $\bb C^n = \{w, z\}$ for $w \in \bb C$ and $z \in \bb C^{n-1}$, of the form 
$$
	w^d + a_1(z)w^{d-1} + \dots + a_d(z) 
$$
where $a_i$ are holomorphic functions on $U \subset \bb C^{n-1}$. If you fix the $z$ coordinate, $f$ is a polynomial in $w$ of degree $d$, with $d$ roots. We will talk more about why this is a desirable form in the next lecture. 
\chapter{Hartogs Theorem and Domains of Holomorphy}
\section*{Lecture 2, Sept 1}
\label{sec:2}
In this lecture, we will go through proofs for Hartogs' and Weierstrass Theorems. \\
\textbf{Theorem (Hartog): }\textit{Let $\epsilon, \epsilon' \in \bb R^n_{\geq 0}$, and $\epsilon_i' > \epsilon_i$, $n \geq 2$. Then the restriction map} 
$$
	\varphi: \mathcal{O}(D_\epsilon) \to \mathcal{O}(D_\epsilon\setminus \overline{D_{\epsilon'}})
$$
\textit{is bijective.}\\
\textbf{Proof: }To prove injectivity, we will use a result from 1 variable complex analysis:\\
\textbf{Theorem (Identity Theorem): }\textit{If $f,g,: U \to \bb C$ are holomorphic functions on an open subset $U \subset \bb C$ such that there exists a non-empty open subset $V \subset U$ such that $f|_V = g|_V$, then $f = g$.}\\\\
Knowing this, if we assume that $\varphi(f) = \varphi(g)$, then if we restrict to a single variable, say the first coordinate, and fix all the others, then $\varphi(f)(z) = \varphi(g)(z)$ for all $z \in D_\epsilon\setminus \overline{D_{\epsilon'}}$. An open set minus a closed set is open, and $\epsilon_i' > \epsilon_i$ implies $D_\epsilon \setminus \overline{D_{\epsilon'}}$ is non empty, so we satisfy the conditions to apply 1-dimensional Identity Theorem, setting $U = D_\epsilon$ and $V =D_\epsilon \setminus \overline{D_{\epsilon'}}$, so that $f = g$, and $\varphi$ is injective. \\
To show surjectivity, define a projection
$$
	\pi: D_\epsilon \setminus \overline{D_{\epsilon'}} \to D_{\hat\epsilon} \setminus \overline{D_{\hat \epsilon'}}
$$
where a hat denotes an omission of the first entry, so this is a projection from $\bb C^n \to \bb C^{n-1}$. Then we have 
$$
	\inv \pi (\hat z) = \begin{cases}
	\Delta_{\epsilon_1}\setminus \overline{\Delta_{\epsilon'_1}} \times \{\hat z\} & z \in \overline{D_{\hat \epsilon'}}\\
	\Delta_{\epsilon 1} \times \{\hat z\} & \text{ else } 
\end{cases}
$$
Then take $f \in \mathcal{O}(D_\epsilon \setminus \overline{D_{\epsilon'}})$, and we want to find a function on $D_\epsilon$ which restricts to $f$ on $D_\epsilon \setminus \overline{D_{\epsilon'}}$, and we will use CIF to define
$$
	g := \frac{1}{2\pi i} \int_{\norm{\zeta} = \frac{\epsilon_1 + \epsilon_1'}{2}} \frac{f(\zeta, \hat z)}{\zeta - z_1}d\zeta \in \mathcal{O}\left(D_{\left(\frac{\epsilon_1 + \epsilon_1'}{2},\hat \epsilon\right)}\right)
$$
So we are applying CIF in one dimension, specifically the first variable, so that $g$ is holomorphic in the first variable, and $f$ is holomorphic in the final $n-1$ variables, so $g$ is holomorphic in each of its variables, and thus is holomorphic on this restricted polydisc. Then, if we restrict to the ``annulus'' polydisc $D_{\left(\frac{\epsilon_1 + \epsilon_1'}{2},\hat \epsilon\right)}\setminus \overline{D_{\epsilon'}}$, the Cauchy Integral Theorem tells us that $g = f$, as required. \mqed
\\
\textbf{Question: }What is the topology of the domain $D_\epsilon \setminus \overline{D_{\epsilon'}}$? \\
If we look in the 2D case, we can define a map
\begin{gather*}
	\bb C^2 \to \bb R^2_{\geq 0}\\
	(z_1,z_2) \mapsto (\norm{z_1}, \norm{z_2})
\end{gather*}
Then the fiber over each point in $\bb R^2_{\geq 0}$ is $S^1 \times S^1$. \\
To answer the question, we know that the polydiscs have the topology of a ball. So if you remove a closed ball of smaller radius, you are left with a space that retracts onto the sphere, so $D_\epsilon \setminus \overline{D_{\epsilon'}}$ is topologically a sphere, $S^{2n-1}$. As such, it is connected and simply-connected. \\
Now we talk about domains of convergence of power series, $\sum_{k \in \bb N^n} a_k z^k$. Since the domain of convergence in $n = 1$ is a disk, we might guess that in $n$ dimensions, the domain of convergence will be a polydisc. To prove this, we will use a lemma:\\
\textbf{Lemma: }\textit{If $w \in \bb C^{n*}$, and}
$$
	\forall\ k,\ |a_k w^k| \leq C
$$
\textit{for some $C$, i.e. there is a uniform bound on the norm of the terms, then $\sum_k a_k z^k$ converges absolutely in $D_w$. }\\
\textbf{Proof: }Same as dimension 1 proof. \\
\mqed
So it turns out that the polydisc guess is not exactly right, but is close. Instead, \\
\textbf{Definition: }Given the map $\kappa: \bb C^n \to \bb R^n_{\geq 0}$ sending $(z_1,\dots,z_n) \mapsto (|z_1|,\dots,|z_n|)$, a \underline{Reinhardt domain} is the pre-image of a domain $U \subset \bb R^n_{\geq 0}$ under $\kappa$. In this case, a domain is just a connected, open subset. \\\\
The fiber of a point $x \in \bb R^n_{\geq 0}$ with all non-zero entries is an $n$-torus. If not all the entries are non-zero, then the number of coordinate axes which $x$ intersects determines the dimension of the resulting torus. These are just the fibers over single points, the Reinhardt domains are the pre-images over any connected, open set, so they can look very crazy. \\
Then we may define\\
\textbf{Definition: }The \underline{Logarithm} map is the map 
\begin{gather*}
	\text{Log}: \bb C^{n*} \to \bb R^n\\
	(z_1,\dots,z_n) \mapsto (\text{log}(|z_1|), \dots, \text{log}(|z_n|)
\end{gather*}
\textbf{Definition: }If $U \subset \bb C^n$ is a Reinhardt domain, then $U$ is \underline{logarithmically convex} if Log$(U \cap C^{n*})$ is a convex domain. \\
\textbf{Proposition:} \textit{If $U$ is the domain of convergence for some power series $\sum_k a_k z^k$, then $U$ is a logarithmically convex Reinhardt domain. In fact, this is an equivalence, but we'll only prove the stated direction.}\\
\textbf{Proof: }Assume that $\sum a_kz^k$ converges for $|z| = \delta$ and $|z| = \sigma$. Then there exists $C$ such that 
$$
	|a_k| \delta^k,\ \ |a_k|\sigma^k < C
$$
Then let $\chi \in \bb R^n_{\geq 0}$ such that 
$$
	\text{log}\chi = \alpha \text{log} \rho + \beta \text{log}\sigma,\ \ \ \ \alpha + \beta = 1
$$
then, if $k = (k_1,\dots,k_n)$,
\begin{gather*}
	\text{log}\chi^k = \text{log}\chi_1^{k_1} \dots \chi_n^{k_n}\\
	= \sum_{i = 1}^n k_i\text{Log}\chi_i\\
	= \alpha \sum k_i\text{log}\rho_i + \beta \sum\text{log}\sigma_i\\
	= \alpha\log\rho^k + \beta\text{log}\sigma^k\\
\leq \alpha \text{log}\frac{C}{|a_k|}\\
|a_k\chi^k| < C
\end{gather*}
The final line implies, by our earlier lemma, that $\sum_k a_kz^k$ converges on $D_\chi$. 
\mqed
\\
Now we will discuss the Identity theorem in $n \geq 2$. \\
\textbf{Theorem: }\textit{If $f,g$ are holomorphic functions on $U \subset \bb C^n$, and $\exists V \subset U$ open such that $f|_V = g|_V$, then $f = g$.}\\
Recall the proof in $n = 1$: We wish to show $\Omega$, the set of points on which $f$ and $g$ disagree, is closed, open, and nonempty in $\bb C$. To see it is closed, we note $f-g$ is a continuous function, and singletons are closed in $T_1$ spaces, the pre-image of a closed set is closed, so $\inv{(f-g)}(0)$ is a closed set, and $\inv{(f-g)}(0) = \Omega$. To show it is open, if we take some $c \in \Omega$, so that $f(c) = g(c)$, then because $f$ and $g$ are holomorphic, we can expand them into a Taylor series, each of which have non-zero radii of convergence (in this case, polyradius, since they will converge on a polydisc), and $f$ and $g$ agree on the polydisc, so $\Omega$ is open. $\Omega$ is non-empty by definition. \mqed\\
\textbf{Proposition: }\textit{For $f: U \subset \bb C^n \to \bb C$ holomorphic and non-constant, $f$ is open. }\\
\textbf{Proof: } If $f$ is non-constant, for any $z \in U$, there is some line through $z$ on which $f$ is non-constant, i.e. there is another point on the line, $w$, such that $f(z) \ne f(w)$. Applying the 1-dimensional open mapping theorem, we have the result. \mqed\\
We will do some preparatory work to talk about Weirstrauss preparation theorem next lecture:\\
\textbf{Lemma: }\textit{Let $\epsilon > \epsilon' > 0$, and $f \in \mathcal{O}(\Delta_\epsilon)$, and $\lambda_1,\dots,\lambda_d \in \Delta_{\epsilon'}$ are the zeros of $f$ counted with multiplicities (so if $\lambda_i$ has multiplicity $r$, then it appears $r$ times in the list $\{\lambda_1,\dots,\lambda_d\}$). Then for $k \geq 0$,}
$$
	\sum_i^n \lambda_i^k = \frac{1}{2\pi i} \int_{|z| = \epsilon'} z^k \frac{f'(z)}{f(z)} dz 
$$
The LHS is what is known as a Newton polynomial. Note that the case of $k = 0$, we recover the typical method of counting zeros.  \\
\textbf{Proof: }By the residue theorem, the RHS is 
$$
	\sum_{w \in \Delta_{\epsilon'}(0)} \text{Res}\left(z^k\frac{f'(z)}{f(z)},w\right)
$$
We will compute this for fixed $\lambda$. In this case, we can rewrite
$$
	f(z) = (z-\lambda)^r h(z)
$$ 
where $h(z) \ne 0$. Then the residue is 
\begin{gather*}
	\text{Res}\left(z^k \frac{f'(z)}{f(z)},\lambda\right) = \text{Res}\left(z^k\frac{r(z-\lambda)^{r-1}h(z) + (z-\lambda)^rh'(z)}{(z-\lambda)^rh(z)},\lambda\right)\\
= \text{Res}\left(z^k\left(\frac{1}{z-\lambda} + \frac{h'(z)}{h(z)}\right),\lambda\right)\\
= \lambda^kr + 0 
\end{gather*}
Then summing over all $\lambda$ gives us the result. 
\mqed
\chapter{Weierstrass Preparation Theorem}
\section*{Lecture 3, Sept 3}
\label{sec:3}Consider the ring of symmetric polynomial functions. This has obvious basis of the elementary symmetric polynomials: if there are $d$ variables, there is one elementary symmetric polynomial of degree $n$ for each $n \leq d$, made by adding products of each variable. For example, the $n = 3$ elementary symmetric polynomial is 
$$
	\sum_{1\leq j < k < l \leq d} \lambda_j\lambda_k\lambda_l
$$
It is a theorem that you can also pick a basis as these Newton polynomials, or ``power sums'', i.e. there are transformations called ``Newton identities'' which express these Newton polynomials in terms of the elementary symmetric polynomials. One can look them up, it becomes complicated with higher degrees. For now, all we need to know is that it can be done. \\
\textbf{Theorem (Weierstrass Preparation Theorem):}\textit{ Adopt the coordinates $(z,w)$ for $z \in \bb C$ and $w \in \bb C^{n-1}$. Then if $U \subset \bb C^{n-1}$, $f \in \mathcal{O}(U \times \Delta_\epsilon)$ such that $f|_{U \times \partial \Delta_{\epsilon}}$ has no zeros of $f$, then $\forall\ \epsilon' < \epsilon$ sufficiently close, $\exists$ a Weierstrass polynomial $g$, such that $f|_{U \times \Delta_{\epsilon'}} = gh$, for some $h \in \mathcal{O}(U' \times \Delta_{\epsilon'})$, for $U' \subset U$, and $h(0) \ne 0$.  }\\
\textbf{Proof: }We may assume that $f|_{U' \times \Delta_{\epsilon'}}$ has no zeros. Then for $w \in U$, let $ \lambda_1(w),\dots,\lambda_{d(w)}(w)$ be the set of zeros of $f|_{\{w\}\times \Delta_{\epsilon'}}$. By the previous lemma, the function $$
 d(w) = \sum_{i = 1}^{d(w)}\lambda_i^0 = \frac{1}{2\pi i}\int_{|z| = \epsilon} \frac{\partial_z f}{f} dz
$$
is locally constant wrt $w$, and if we take $U$ connected, it is independent of $w$. So we define $g$ pointwise:
\begin{gather*}
	g(z,w) = \prod_{i = 1}^d\Big(z-\lambda_i(w)\Big) = z^d + \alpha_1(w)z^{d-1} + \dots + \alpha_d(w)\\
	\text{where}\  \alpha_i = (-1)^i\delta_i(\lambda_1,\dots,\lambda_d)
\end{gather*}
where $\delta_i$ is the elementary symmetric polynomial. Then the fact from last lecture: The elementary symmetric functions can be expressed in terms of the Newton polynomials. But as the lemma showed, the Newton polynomials, for every $k$, are just integrals, and as such are holomorphic. So the $\alpha_i$ are holomorphic, and so is $g$. Then defining $h = \frac{f}{g}$ gives the result. \mqed\\
The reason this theorem is important in complex analysis is because it gives us tools to study the 0 loci of holomorphic functions, so-called analytic sets. It is saying that to study the zeros of $f$ in this region, it is sufficient to study $g$, a Weierstrass polynomial, which is a factor of $f$. \\
\textbf{Example: }Apply WPT to the polynomial $f(z_1,z_2) = z_1^3z_2 + z_1z_2 + z_1^2z_2^2 + z_2^2 + z_1z_2^3$\\\\
We recall that given a real vector space, $V$, we can always get a complex vector space by complexifying $V$ to $V_\bb C := V \otimes_ \bb R \bb C$. Note that there is a canonical isomorphism $V_\bb C := V \otimes_ \bb R \bb C = V \oplus V$ decomposing $V_\bb C$ into ``real'' and ``complex'' parts. Then the complex structure on $V \oplus V$ is the map $(v,w) \to (-w,v)$. If we think of $(v,w)$ as $v + iw$, this choice of complex structure is natural. This is an important point because, given an abstract complex vector space, there is no notion of real or imaginary parts. The complex vector spaces which are obtained as tensor products of real vector spaces have this natural decomposition. \\
\textbf{Definition: }Given a complex vector space, $V$, a \underline{real structure} on $V$ is a conjugate linear involution $\kappa: V \to V$. \\\\
If an abstract complex vector has a real structure, then the fixed locus of $\kappa$, $V^\kappa$, defines an isomorphism 
$$
	V^\kappa \otimes_{\bb R} \bb C \to V
$$
which gives a decomposition of $V$ into real and imaginary parts. Any complex vector space can be given a real structure, so that one may decompose vectors into real and imaginary parts, but only those which arise as a tensor product have this structure a priori. If handed an abstract complex vector space, one must impose this structure by picking a basis of $V$. But what would happen if you wanted to complexify a complex vector space? This happens already in complex manifold theory, where we study the complexified tangent bundle. But the tangent bundle already has a complex structure, that's the definition of a complex manifold! If you complexify a complex vector space, $V$, you get an isomorphism $V \otimes _ \bb R \bb C \cong
V \oplus \overline V$, where $\overline V$ is the complex vector space with the same underlying real vector space as $V$, but with the opposite complex structure, $-I$.\\
Finally, we will talk about analytic sets\\
\textbf{Definition: }An \underline{analytic set} $Z \subset U$ is a set such that $\forall\ z \in U$, $\exists V \subset U$ open such that $\exists f_1,\dots,f_\gamma \in \mathcal{O}(V)$, $Z \cap V = \{z \in V\ |\ f_1(z) = \dots = f_\gamma(z) = 0\}$.\\\\
So an analytic set locally looks like the zero locus of finitely many holomorphic functions.\\
\textbf{Definition: }The \underline{germ} of an analytic set at $0 \in \bb C^n$ is an equivalence class of pairs $(U,Z)$, where $U$ is an open neighborhood of $0 \in \bb C^n$ and $Z$ is an analytic subset of $U$. The equivalence relation imposed is $(U,Z) \sim (U',Z')$ iff $\exists V \subset (U \cap U')$ a neighborhood of 0 such that $Z \cap V = Z' \cap V$.\\\\
So the usual notion of a germ, that is setting things to be equivalent if they agree locally, but now locally means ``on an analytic subset''. If $\alpha_i$ are elements of a ring, we denote $I(\alpha_i$) to be the ideal generated by those elements. The germ of an analytic set $Z$ is denoted $(Z,0)$, so for example, the germ of a zero locus of an ideal $I$ is written $(Z(I),0)$. \\
\textbf{Lemma: }\textit{The set of germs is in bijection with the set of finitely generated ideals in the ring of convergent power series of $\bb C^n$.}\\
\textbf{Proof: }Given a germ of an analytic set, let $f_1,\dots,f_n$ be those functions which realize the definition of an analytic set, say at a point $z$. Then $(f_1,\dots,f_n)$ generated a finitely generated ideal in the ring of convergent power series, since $f_i$ are holomorphic. Conversely, given a finitely generated ideal let $f_1,\dots,f_n$ be a finite generating set. Then $Z(f_1,\dots,f_n) := \{z \in U\ |\ f_i(z) = 0\}$ is analytic, and so we can take its germ. To do this, we made a choice of generators $f_i$, but the germ is well defined under this choice. This comes from the general fact that if $I$ is finitely generated, then $Z(I)$ is well defined: If $g_i$ is another generating set, then 
\begin{gather*}
	\forall\ \alpha, f_\alpha = \sum_i \lambda_i g_i,\ \  \ \ \text{for  } \lambda_i \in \mathcal{O}_{\bb C^n,0}\\
\Rightarrow Z(f_i) \subset Z(g_i)
\end{gather*}
and vice versa\footnote{Siebert did not prove the statement that $(Z(I),0)$ was well defined, and I doubt my own proof here. I used neither the fact that we took germs of $Z(I)$ instead of just $Z(I)$, nor the fact that it was finitely generated. If my proof is correct, then the bijection statement could have been made without any mention of germs, which is probably wrong. }. \mqed
This lemma is very reminiscint of Hilbert's Nullstellensatz. \\\\
\textbf{Definition: }If $I$ is an ideal, the \underline{radical} of $I$ is the set $\sqrt I := \{z \in R\ |\ \exists d > 0 \text{ s.t. } z^d \in I\}$, and if $I$ is an ideal such that $I = \sqrt I$, then we call $I$ a \underline{radical ideal}. \\\\
\textbf{Lemma: }$Z(I) = Z(\sqrt I)$.  \\
\textbf{Proof: }
\begin{gather*}
	z_0 \in Z(I) \Rightarrow f(z_0) = 0 \forall\ f \in I\\
	\forall\ g \in \sqrt I, g^k = f \text{ for some } f \in I\\
	\Rightarrow g^k(z_0) \equiv \underbrace{g(z_0) \dots g(z_0)}_{\text{n times}} = f(z_0) = 0 \Rightarrow g(z_0) = 0
\end{gather*}
Conversely, $I \subset \sqrt I \Rightarrow 
Z(I) \subset Z(\sqrt I)$. \mqed \\
Properties of $\mathcal{O}_{\bb C^n,0}$: i) It is a UFD, ii) It is Noetherian, i.e. all ideals are finitely generated. \\
In the future, we will study the basic correspondence we have just outlined:\\
\begin{alignat*}{1}
	\left\{I \subset \mathcal{O}_{\bb C^n,0}\ |\ I = \sqrt I\right\} &\longleftrightarrow
\{(Z,0)\subset (\bb C^n,0) \text{ analytic }\}\\
	I &\longmapsto Z(I)\\
	\{f \in \mathcal{O}_{\bb C^n,0}\ |\ Z \subset Z(f)\} =:I(Z) &\longmapsfrom (Z,0)
\end{alignat*}

\chapter{Lec 4}
\section*{Lecture 4, Sept 8}
\label{sec:4}
If we have a holomorphic function $f: U \subset \bb C^m \to \bb C^n$, and adopt the coordinates $(z_i)$ on the domain and $(w_i)$ on the codomain, with $z_i = x_i + iy_i$ and $w_i = u_i + iv_i$, and $f_i = g_i + ih_i$, the Jacobian of $f$ is written as 
$$
	J_ \bb R(f)(z) = \begin{pmatrix}	\partial_{x_j} g_i & \dots & \partial_{y_j} g_i \\ \vdots & & \vdots \\ \partial _{x_j}h_i & \dots & \partial_{y_j} h_i\end{pmatrix} \in M(2n \times 2m, \bb R)
$$
so this is a real matrix, and suppose we want to study its complexification. We recall that $\cdot \otimes_\bb R \bb C$ is a functor, so that we may apply it to maps as well, and it acts on maps by tensoring with the identity on the second component, so 
$$
	J_\bb C(f)(z) = J_\bb R(f)(z) \otimes_\bb R Id_\bb C : V \otimes_\bb R \bb C \to W \otimes_\bb R \bb C
$$
Note\footnote{I actually don't know why this is. I know there's a formula to tensor two matrices together, but there has to be a better explanation than that. Maybe thinking about det as the map on the top ext power}: det $J_\bb R(f)(z) = $ det $J_\bb C(f)(z)$. We can write down this Jacobian for any real differentiable map. But what if $f$ also happens to be holomorphic? As we discussed in the first lecture\footnote{Maybe it was second I don't remember}, we have 
$$
	J_\bb C(f)(z) = \begin{pmatrix}\partial_{z_j} f_i & \dots & \partial_{\overline{z_j}}\\ \vdots & & \vdots \\ \partial_{z_j} \overline{f_j} & \dots & \partial_{\overline{z_j}} \overline{f_j} \end{pmatrix} = \begin{pmatrix}\partial_{z_j} f_i & 0 \\ 0 & \overline{\partial_{z_j} f_i} \end{pmatrix}
$$
So the Jacobian is really determined by one, smaller matrix in the upper left, which we will denote $J(f)(z)$. Then of course, det $J_\bb C(f)(z) = |$det $J(f)(z)|^2 \geq 0$. As a result, $f$ is orientation preserving iff it is non-singular, and it cannot reverse orientation. We will see later that this is exactly the reason that complex manifolds are always orientable. \\
\textbf{Definition: }A map $f: U \to V$, for $U,V \subset \bb C^n$ open is \underline{biholomorphic} if it is holomorphic and bijective, and its inverse is holomorphic. \\\\
This is the complex analogue of a diffeomorphism. We recall the \\
\textbf{Theorem (Inverse Function Theorem:)} \textit{If $f$ is a map $f: U \to V$ for $U,V \subset \bb C^n$, and $z$ is a regular value (or equivalently\footnote{It took me about 30 minutes to figure out, but they're equivalent because $f$ is a map from $\bb C^n \to \bb C^n$. Felt quite silly upon realizing this.}, det $J(f)(z) \ne 0$), then there exist open sets $U',V' \subset \bb C^n$ such that $f|_{U'}$ is a biholomorphism onto $V'$. }\\
\textbf{Proof: }We note that $z$ is a regular value of $f$ iff det $J_\bb R(f)(z) \ne 0$, so the real inverse function theorem tells us that there exists a smooth inverse to $f$, $g: V' \to U'$. To see that it is also holomorphic, we show it satisfies the CR equations\footnote{The first equality holds becuase the identity map is holomorphic}: 
\begin{gather*}
	0 = \partial_{\overline{z_j}} (\inv f \circ f)\\
	= \sum_{k = 1}^n (\partial_{w_k} \inv f \cdot \partial_{\overline{z_j}} f_k + \partial_{\overline{w_k}} \inv f \cdot \partial_{\overline{z_j}} \overline{f_k})\\
	= \sum_{k =1 }^n\overline{\partial_{z_j}f_k} \cdot \partial_{\overline{w_k}} \inv f\\
	\Rightarrow J(f) = (\partial_{z_j}f_k)_{ij} \text{ invertible } \Rightarrow \forall\ k\ \  \partial_{w_k} \inv f = 0
\end{gather*}
so that $\inv f$ is holomorphic. \mqed\\
\textbf{Lemma: }\textit{If $f: U \to V$ is holomorphic and bijective, then $f$ is a biholomorphism.}\\\\
We note that in the real case (replacing holomorphic and biholomorphic with smooth and diffeomorphic, respectively), this is not true. For example, take $y = x^3$. \\
\textbf{Theorem (Implicit Function Theorem)\footnote{Dr. Siebert notes that in Germany, during oral exams for undergraduates, students would reliably fail at correctly formally stating the implicit function theorem. Indeed, this exact scenario happened to me in an undergraduate class last year. one part of one of our problems on an exam was to simply state the implicit function theorem, and i only received about half credit on that part.}: } \textit{Let $U \subset \bb C^m \times \bb C^n$ have coordinates $(z,w)$, and $f: U \to \bb C^n$ be holomorphic. If $J(f) = (\partial_{w_j} f_i))_{ij}$ is invertible at $(z_0,w_0) \in U$, and $f(z_0,w_0) = 0$, then $\exists\ U_1 \subset \bb C^m, U_2 \subset \bb C^n$ open, $U_1 \times U_2 \subset U,\ (z_0,w_0) \in U_1 \times U_2$, $g: U_1 \times U_2$ such that}
$$
	\{(z,w) \in U_1 \times U_2\ |\ f(z,w) = 0 \} = \Gamma_g = \{(z,g(z))\ |\ z \in U_1\}
$$
\textbf{Proof: }Again we have the existence of such a function $g$ from the real version of the implicit function theorem, and apply the chain rule to show that $g$ is in fact holomorphic.\mqed\\
We will now work our way up to the analytic Nullstellensatz. We recall that, essentially by definition, $\mathcal{O}_{\bb C^n, 0} = \bb C\{z_1,\dots,z_n\}$. \\
\textbf{Definition: }A ring is called \underline{local} if it has a unique maximal ideal. \\\\
\textit{Lemma: The ring described above is local.}\\
\textbf{Proof: } The unique maximal ideal is 
$$
	\mathcal{M}:= \left\{f = \sum a_Iz^I\ |\ a_0 = 0\right\} = \{f \in \mathcal{O}_{\bb C^n,0}\ |\ f(0) =0 \}
$$
\mqed\\
This defines an ideal. To show it is maximal, there is a well defined evaluation homomorphism:
\begin{gather*}
	ev_0: \mathcal{O}_{\bb C^n,0} \to \bb C\\
f \mapsto f(0) = a_0
\end{gather*}
We see that the quotient $\mathcal{O}_{\bb C^n,0} / \mathcal{M} \cong \bb C$, and we recall that an ideal is maximal iff the quotient ring is a field, which $\bb C$ is. \mqed
We note that this property of locality is not unique to holomorphic functions: Smooth and continuous functions also share this property, for example. \\
\textbf{Lemma: }\textit{$\mathcal{O}_{\bb C^n,0}$ is an integral domain}\\
\textbf{Proof: }There is a tedious, algebraic method to prove this lemma, but the geometric way is cleaner, via the identity theorem. WLOG, we may assume $f,g \in \mathcal{O}(D_\epsilon)$. Then if $f \not \equiv 0,\ \exists\ z \in D_\epsilon$ such that $f(z) \ne 0 \Rightarrow \exists D_{\epsilon'}(z)$ such that $f|_{D_{\epsilon'}(z)	} \ne 0$. But then $g|_{D_{\epsilon'}(z)} \equiv 0$, so the identity theorem shows $g = 0$. \mqed\\
\textbf{Lemma: }\textit{$\mathcal{O}_{\bb C^n,0}$ is a UFD.}\\
\textbf{Idea of Proof: }The Wierstrass Preparation Theorem reduces this proof to a known statement about polynomials. \mqed\\
\textbf{Definition: }A \underline{hypersurface} is the set of zeros $Z(f) \subset U \subset \bb C^n$ for $f \in \mathcal{O}(U\setminus \{0\})$. The germ of a hypersurface is then the germ of the zero locus. \\\\
\textbf{Corollary: }\textit{Any germ of hypersurfaces decomposes uniquely into germs of irreducible hypersurfaces.}\\
\textbf{Proof: }If we decompose $f$ into irreducibles, $f = g_1\dots g_r$, then $Z(f) = \cup Z(g_i)$. Then we must show the $Z(g_i)$ are irreducible. To do so, we must use a lemma about hypersurface containment:\\
\textbf{Lemma: }\textit{If $f,g \in \mathcal{O}_{\bb C^n,0}$ and $g$ irreducible, then $Z(g) \subset Z(f) \Rightarrow g\ |\ f$.  }\\\\
With this lemma, the result can be found. \mqed\\
\chapter{Lec 5}
\section*{Lecture 5, Sept 10}
\label{sec:5}
I missed lecture 5, sadge.
\chapter{Lec 6}
\section*{Lecture 6, Sept 15}
\label{sec:6}
\textbf{Theorem (Local Finite Mapping/Noether Normalizing): }\textit{Let $X \subset (\bb C^n,0)$ be a germ of analytic sets. Then there exists $d \leq n$, and a linear coordinate system $(z_1,\dots,z_d,z_{d+1},\dots,z_n)$ such that the projection}
$$
	\pi: \bb C^n \to \bb C^d,\ \ (z_1, \dots, z_n) \mapsto (z_1,\dots,z_d)
$$
\textit{induces a proper, open surjection $X \to (\bb C^d, 0)$ with finite fibers, i.e. is a branched cover. We refer to $d$ as the dimension of $X$.  }\\\\
\textbf{Non-example: }Take $\pi:\bb C^3 \to \bb C^2$ such that $(x,y,z) \mapsto (x,y)$, and take $X = Z(y-zx)$. Then $X$ is irreducible, but $\pi$ does not have finite fibers: $\inv\pi(0,0) = \{0,0\} \times \bb C$. This is an example of a blow-up. The theorem does not apply because $\mathcal{O}_{\bb C^2,0} \to \mathcal{O}_{X,0}$ is not an integral ring extension, which is a necessary step for the algebraic proof of the above theorem. \\\\
A priori, we may believe $d$ depends on the choice of projection. There are 3 ways to show that this notion of dimension is well defined: a) We can show that outside of a nowhere dense, analytic subset, this is an unbranched covering. Then working locally, if we assume there is another covering $\pi'$ of dimension $d'$, then we have a diffeomorphism from a subset of $\bb C^d$ to $\bb C^{d'}$, and we are done. For the second method, we define\\
\textbf{Definition: }The \underline{Krull dimension} of a commutative ring $R$ is the supremum of the lengths of all chains of prime ideals:\\
\begin{gather*}
	\text{dim }R  = \sup\{k\ |\ f_0 \subset f_1 \subset \dots \subset f_k\in \mathcal{O}_{X,0}\} \\\text{ where } f_i \text{ are prime ideals, and the containments are proper}
\end{gather*}
\\
So 0-dimensional rings correspond to maximal ideals. If you take a hypersurface inside $X$, that has codimension 1, then you continue until you reach an irreducible component. So if $X$ is irreducible, $\mathcal{O}_{X,0}$ is an integral domain. The final way of showing this is related to stratifications.\\
\textbf{Definition: }If $X$ is an analytic subset, then the \underline{singular locus} $$X_{\text{sing}} = \{x \in X\ |\ X \text{ is not a submfld at }x\} \subset X$$ is the locus where $X$ is not a submanifold. \\\\
$X_{\text{sing}}$ can have any codimension. For example, take two copies of $\bb C^2$ and have them meet at the origin of $\bb C^4$ transversely, this has codim 2. Of course, the containment $X_{\text{sing}} \subset X$ must be a proper containment. Then we may take the series of successive singularities: the next step would be $(X_{\text{sing}})_{{\text{sing}}}$. Each set is also analytic, thought that must be proved, and the dimension decreases with each step, so this series will always terminate. Then we define the dimension of $X$ to be complex dimension dim $X\setminus X_{\text{sing}}$.\\\\
So now we have an idea of what the zero loci of holomorphic functions in severeal comlex variables looks like. They are closed, they admit these stratifications, locally they are coverings of domains in $\bb C^d$, and they have dimension $d$. \\\\
Onto complex manifolds. 
\chapter{NOT FINISHED}
\section*{Lecture 6, Sept 17}
\label{sec:7}
We will start with projective space. Siebert remarks that $\bb CP^n$ is arguably the most important complex manifold, even moreso for compact complex manifolds. As a set, 
$$
	\bb CP^n = (\bb C^{n+1}\setminus \{0\})\Big/ \bb C^*
$$
where $\bb C^*$ acts diagonally. This induces the quotient topology. We note there is a surjection $S^{2n+1} \to \bb CP^n$, the antipodal map, which implies the latter is compact. The standard charts on $\bb CP^n$ is 
$$
	U_i := \{[z_0,\dots,z_n]\in \bb CP^n\ |\ z_i \ne 0\}
$$
Clearly these $U_i$ cover $\bb CP^n$, and re biholomorphic to $\bb C^n$ via 
\begin{gather*}
	\varphi_i :U_i \to \bb C^n \text{ parameterized by } w_0,\dots\hat w_i, \dots, w_n\\
[z_0,\dots,z_n] \mapsto \frac{1}{z_i}(z_0,\dots,\hat z_i, \dots, z_n) 
\end{gather*}
It is easily seen that the transition functions are biholomorphic. \\
Similarly, if $V$ is a finite dimensional complex vector space, then can define $\bb CP(V)$ via charts, but we then need to worry about change of basis. If we have a change of basis $T: \bb C^{n+1} \to \bb C^{n+1}$, i.e. a linear isomorphism, we get a functor from complex vector spaces to comlex manifolds, $\bb P$, which sends
$$
	T \mapsto \bb P(T):\bb CP^n \to \bb CP^n
$$
is a biholomorphism. Note we induce a map on the quotient simply by linearity. Another way to view this, we have a group homomorphism 
$$
F: GL(n+1, \bb C) \to \{\text{biholomorphisms of }\bb CP^n\}
$$
What is Ker $F$? Clearly, all the scalar diagonal matrices, i.e. those of the form $cA$ for $c \in \bb C^*$ and $A \in GL(n,\bb C^{n+1})$, because multiplication by a scalar prerves the $\bb CP^n$ class, by definition. It turns out this is the entire kernel, and the quotient by this normal subgroup Ker $F$ is called the projective linear group, $PGL(n+1,\bb C^{n+1})$. \\\\
There is an easy way to write down submanifolds of projective space via the homogeneous coordinates. \\
\textbf{Definition: }If $f \in \bb C[z_0,\dots,z_n]$, then it is called \underline{homogeneous of degree $d$} if $\exists d\ $ s.t. $\forall\ \lambda \in \bb C^*$, 
$$
	f(\lambda z_0,\dots, \lambda z_n) = \lambda^d f(z_0,\dots,z_n)
$$
\\
If $f$ is as above, we may now define the zero locus $Z(f):=\{[z_0,\dots,z_n] \in \bb CP^n\ |\ f(z_0,\dots,z_n) = 0 \}$. Note,$f$ cannot be a function on $\bb CP^n$, by the maximum principal. However, locally, we can still take its zero locus via charts: on $U_i$, $\varphi_i(Z(f)\cap U_i) = Z(f_i)$, where $f_i(w_0,\dots,\hat w_i,\dots,w_n) = f(w_0, \dots, 1, \dots, w_n)$ with the 1 in the $i$th index. \\
\textbf{Definition: }A \underline{complex hypersurface} in $\bb CP^n$ is a set of the form $Z(f)$ for $f \in \bb C[z_0,\dots,z_n]\setminus \bb C$. As usual, given an ideal $S \subset \bb C[z_0,\dots,z_n]$, we have a corresponding zero locus, 
$$
Z(S) := \bigcap_{f \in S} Z(f)
$$
\chapter{Lec 8}
\section*{Lecture 8, Sept }
\label{sec:7}
\end{document}